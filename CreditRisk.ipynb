{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditRisk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaF2JB7ToVmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a371ad7b-6c2d-49f9-cadf-58cd0c71c5cc"
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 204.2MB 75kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 55.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muTi94vT_I_x"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import  math\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import * \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_q_ejMfaDQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa4cdc5d-3e30-44ae-eef5-c9ad8a656b9b"
      },
      "source": [
        "sc = SparkContext(appName=\"Credit Risk\")\n",
        "sqlContext = SQLContext(sc)\n",
        "\"\"\"defining the sparkcontext which used for establishing a connection to the spark cluster and sql context which enables us to perform sql-like operations on our dataset\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'defining the sparkcontext which used for establishing a connection to the spark cluster and sql context which enables us to perform sql-like operations on our dataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HBvaWRj8_kCj",
        "outputId": "31a739fc-9f00-4e32-e90a-cbf2a857554d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\"since the size of the dataset is large, in order to upload the dataset, we store it in a google drive and mount it on colab\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'since the size of the dataset is large, in order to upload the dataset, we store it in a google drive and mount it on colab'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR3xIelg_sHw"
      },
      "source": [
        "data = sqlContext.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/content/drive/MyDrive/BigDataProject/credit_card_approval1.csv\")\n",
        "# reading the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC_y50hiqy_T"
      },
      "source": [
        "from pyspark.sql.functions import rand\n",
        "data = data.orderBy(rand())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3uqGPRSAhnB",
        "outputId": "7bce413a-17b9-49af-e02d-1dde6ab6719c"
      },
      "source": [
        "data.show(n=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+----------+------------+------+------+\n",
            "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|       JOB|BEGIN_MONTHS|STATUS|TARGET|\n",
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+----------+------------+------+------+\n",
            "|5053861|          M|           Y|              Y| 2+ children|        121500.0|Secondary / secon...|             Married|House / apartment|    -10991|         -637|         1|              0|         0|         0|  Laborers|          -8|     C|     0|\n",
            "|5126220|          F|           N|              N| No children|        990000.0|    Higher education|             Married|House / apartment|    -22635|        -2357|         1|              1|         1|         0|Core staff|          -5|     0|     0|\n",
            "|5149158|          M|           Y|              Y| No children|        247500.0|Secondary / secon...|             Married|House / apartment|    -10952|        -3577|         1|              1|         0|         0|  Laborers|         -23|     2|     1|\n",
            "|5117444|          M|           Y|              N| No children|        180000.0|Secondary / secon...|             Married|House / apartment|    -20037|        -2349|         1|              1|         1|         0|   Drivers|         -53|     0|     0|\n",
            "|5036469|          M|           Y|              N| No children|        112500.0|Secondary / secon...|Single / not married|House / apartment|    -20333|        -1546|         1|              0|         0|         0|   Drivers|         -19|     5|     1|\n",
            "|5065518|          F|           Y|              N|  1 children|        202500.0|    Higher education|             Married| Rented apartment|     -9510|        -2878|         1|              0|         0|         0|  Laborers|         -31|     5|     1|\n",
            "|5099907|          F|           N|              Y| 2+ children|        112500.0|   Incomplete higher|             Married|House / apartment|    -10927|        -1860|         1|              0|         0|         0|Core staff|         -34|     C|     0|\n",
            "|5068234|          M|           N|              Y|  1 children|        112500.0|Secondary / secon...|             Married|House / apartment|    -13885|         -232|         1|              0|         0|         0|  Laborers|          -7|     C|     0|\n",
            "|5125453|          F|           N|              Y| No children|        337500.0|    Higher education|Single / not married|House / apartment|    -16590|         -438|         1|              0|         1|         1|  Managers|          -8|     0|     0|\n",
            "|5054179|          M|           Y|              N|  1 children|        135000.0|    Higher education|             Married|House / apartment|    -12241|        -1581|         1|              1|         0|         0|  Managers|         -18|     X|     0|\n",
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+----------+------------+------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqhjxZYnzGBt"
      },
      "source": [
        "def FindCount(rows):\n",
        "    \"\"\"For each type of test variable in the dataset, the cnt variable is incremented\"\"\"\n",
        "    cnt = {}  \n",
        "    for r in rows:\n",
        "        # the last column, i.e, the target column is the lab for the dataset we have chosen\n",
        "        lab = r[-1]\n",
        "        if lab not in cnt:\n",
        "            cnt[lab] = 0\n",
        "        cnt[lab] += 1\n",
        "    return cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOKUIBdrzLwB"
      },
      "source": [
        "def label_counts(rows):\n",
        "    \"\"\"For each type of test variable in the dataset, the count variable is incremented\"\"\"\n",
        "    cnts = {}  \n",
        "    for r in rows:\n",
        "        # the last column, i.e, the target column is the lab for the dataset we have chosen\n",
        "        lab = r[-1]\n",
        "        if lab not in cnts:\n",
        "            cnts[lab] = 0\n",
        "        cnts[lab] += 1\n",
        "        sorted_res = sorted(cnts, key=cnts.__getitem__, reverse=True)\n",
        "    return sorted_res[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UuJpWF3zWqx"
      },
      "source": [
        "def CheckNumeric(value):\n",
        "    #Checking for numeric attributes\n",
        "    return isinstance(value, int) or isinstance(value, float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz5Gxnws3q57"
      },
      "source": [
        "class criterion:\n",
        "    \"\"\"Inorder to partition a datset, the right questions are required.\n",
        "    This 'criterion' class assigns and records a number and a value for a column. The algorithm makes use of\n",
        "    this matching method to compare the feature value in an example to the feature value stored in the\n",
        "    crit. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, column, value, header):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "        self.header = header\n",
        "\n",
        "    def CompAndMatch(self, example):\n",
        "        \"\"\"A matching method to compare the feature value in an example to the feature value stored in the crit\"\"\"\n",
        "        v = example[self.column]\n",
        "        if CheckNumeric(v):\n",
        "            return v >= self.value\n",
        "        else:\n",
        "            return v == self.value\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"In order to print the crit in a user readable format, this method is used.\"\"\"\n",
        "        cond = \"==\"\n",
        "        if CheckNumeric(self.value):\n",
        "            cond = \">=\"\n",
        "        return \"Is %s %s %s?\" % (\n",
        "            self.header[self.column], cond, str(self.value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBrcRHOZ3u8i"
      },
      "source": [
        "def datasetPartition(rows, crit):\n",
        "    \"\"\"This method is used to perform the partitioning of the dataset\n",
        "    We are reading each row in the dataset and comparing them with the criteria. If they are same,\n",
        "    append it to 'rows_T', otherwise, append it to 'rows_F'.\n",
        "    \"\"\"\n",
        "    rows_T, rows_F = [], []\n",
        "    for r in rows:\n",
        "        if crit.CompAndMatch(r):\n",
        "            rows_T.append(r)\n",
        "        else:\n",
        "            rows_F.append(r)\n",
        "    return rows_T, rows_F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_9DFpr4rgD"
      },
      "source": [
        "def Cal_GiniImp(rows):\n",
        "    \"\"\"A method to calculate the Gini Impurity.\n",
        "    Definition: Gini Impurity is a measurement of the likelihood of an incorrect classification of a new instance of a random variable,\n",
        "     if that new instance were randomly classified according to the distribution of class labels from the data set.\n",
        "    \"\"\"\n",
        "    cnts = FindCount(rows)\n",
        "    imp = 1\n",
        "    for lb in cnts:\n",
        "        lb_prob = cnts[lb] / float(len(rows))\n",
        "        imp -= lb_prob**2\n",
        "    return imp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4Gtz744uO8"
      },
      "source": [
        "def CalcEntropy(rows):\n",
        "    \"\"\"We are calculating the entropy of each attribute in this function\n",
        "    The formula for entropy is given by summation 1 to n of -pilog2pi\n",
        "    \"\"\"\n",
        "    cnts = FindCount(rows)\n",
        "    imp = 0\n",
        "    for lb in cnts:\n",
        "        lb_prob = cnts[lb] / float(len(rows))\n",
        "        imp += lb_prob * math.log(lb_prob, 2)\n",
        "    return -imp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QmAMdX354i1"
      },
      "source": [
        "def Calc_InfoGain(left, right, unc_curr):\n",
        "    \"\"\"A method to calculate the Information Gain for the attribute.\n",
        "    Note: Information Gain can be defined as the uncertainty of the starting node,\n",
        "     minus the weighted imp of two child nodes.\n",
        "     Info Gain is calculated by the formula Entropy(X)-Entropy(T,X)\n",
        "    \"\"\"\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "    return unc_curr - p * Cal_GiniImp(left) - (1 - p) * Cal_GiniImp(right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf9tR4bC58fr"
      },
      "source": [
        "def best_sp(rows, header):\n",
        "    \"\"\"This is used to determine the best splitting point that is to be performed next on the decision tree.\n",
        "    We choose the property with the highest info gain to be the next edge of the decision tree.\"\"\"\n",
        "    highest_gain = 0  # keep track of the highest gain\n",
        "    best_criterion = None  # keep track of the feature / value that gives the highest gain\n",
        "    unc_curr = Cal_GiniImp(rows)\n",
        "    no_of_feat = len(rows[0]) - 1  # number of columns\n",
        "\n",
        "    for col in range(no_of_feat):  # repeat for each feature\n",
        "\n",
        "        values = set([r[col] for r in rows])  # For each column, the unique values\n",
        "\n",
        "        for v in values:  # repeat for each value\n",
        "\n",
        "            crit = criterion(col, v, header)\n",
        "\n",
        "            # splitting the dataset using the datasetPartition method\n",
        "            rows_T, rows_F = datasetPartition(rows, crit)\n",
        "\n",
        "            # If the dataset is not partitioned, skip this split\n",
        "            \n",
        "            if len(rows_T) == 0 or len(rows_F) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculating the information gain from this split using Calc_InfoGain method\n",
        "            gain = Calc_InfoGain(rows_T, rows_F, unc_curr)\n",
        "\n",
        "            # The choice of > or >= is upto the user and the structure\n",
        "            # of the tree slightly changes accordingly.\n",
        "            \n",
        "            if gain >= highest_gain:\n",
        "                highest_gain, best_criterion = gain, crit\n",
        "\n",
        "    return highest_gain, best_criterion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNcnyFhs5_yU"
      },
      "source": [
        "class Leaf_node:\n",
        "    \"\"\"The leaf node contains the target variable and is used to classify the data entry.\n",
        "    This keeps track of a dictionary of the class -> number of times\n",
        "    it appears in the rows from the training data that reach this leaf.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rows, id, Tree_depth, lab=\"\"):\n",
        "        self.preds = FindCount(rows)\n",
        "        self.lab_predicted = label_counts(rows)\n",
        "        self.id = id\n",
        "        self.Tree_depth = Tree_depth\n",
        "        self.lab = lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDS7FV-f6Dpd"
      },
      "source": [
        "class Dec_Node:\n",
        "    \"\"\"This is the class that actually holds the decision tree that we are going to create in this project.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,crit,branch_T,branch_F,Tree_depth,id,rows,pruned=0):\n",
        "        self.crit = crit\n",
        "        self.branch_T = branch_T\n",
        "        self.branch_F = branch_F\n",
        "        self.Tree_depth = Tree_depth\n",
        "        self.id = id\n",
        "        self.rows = rows\n",
        "        self.pruned = pruned\n",
        "        self.Tree_depth = Tree_depth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83uR_Vin6G0t"
      },
      "source": [
        "def build_tree(rows, header, Tree_depth, id=0):\n",
        "    #Building the decision tree.\n",
        "    \n",
        "    # Tree_depth which is the depth of the decision tree intialized as 0\n",
        "    # dataset is partitioned based on each each unique attribute\n",
        "    # we calculate the info gain,\n",
        "    # and finally return the crit or split criterion that produces the highest gain.\n",
        "\n",
        "    gain, crit = best_sp(rows, header)\n",
        "\n",
        "    # Base case\n",
        "    # The case with no further gain\n",
        "    # A leaf is returned once no further questions can be asked\n",
        "    if gain == 0:\n",
        "        return Leaf_node(rows, id, Tree_depth,header)\n",
        "\n",
        "    # Once the code is run to this part,  a useful feature / value\n",
        "    # to datasetPartition the dataset is obtained.\n",
        "    # nodeLst.append(id)\n",
        "    rows_T, rows_F = datasetPartition(rows, crit)\n",
        "\n",
        "    # Building the true branch recursively\n",
        "    branch_T = build_tree(rows_T, header, Tree_depth+1,2*id+2)\n",
        "\n",
        "    # Building the false branch recursively\n",
        "    branch_F = build_tree(rows_F, header, Tree_depth+1,2*id+1)\n",
        "\n",
        "    # Return the decision node\n",
        "    # Saves the best feature / value to ask a question,\n",
        "    # inorder to barnch further\n",
        "    return Dec_Node(crit, branch_T, branch_F, Tree_depth, id, rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS6ZiLS26J_r"
      },
      "source": [
        "def Tree_Pruning(node, pruningList):\n",
        "    \"\"\" build and optimize the decision tree through parameter tuning\n",
        "    \"\"\"\n",
        "\n",
        "    # Base case\n",
        "    # if we reach the leaf node\n",
        "    if isinstance(node, Leaf_node):\n",
        "        return node\n",
        "    # if we reach a pruned node\n",
        "    if int(node.id) in pruningList:\n",
        "        return Leaf_node(node.rows, node.id, node.Tree_depth, node.crit.value)\n",
        "\n",
        "    # recursive call for a true branch\n",
        "    node.branch_T = Tree_Pruning(node.branch_T, pruningList)\n",
        "\n",
        "    # recursive call for a false branch\n",
        "    node.branch_F = Tree_Pruning(node.branch_F, pruningList)\n",
        "\n",
        "    return node"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Szp0N_6NQM"
      },
      "source": [
        "def TFbranch_classify(r, node):\n",
        "    \"\"\"A function to determine which branch is the best course of action\"\"\"\n",
        "\n",
        "    # Base case\n",
        "    # if we reach the leaf node\n",
        "    if isinstance(node, Leaf_node):\n",
        "        return node.lab_predicted\n",
        "\n",
        "    # We determine the course of action by comparing the \n",
        "    # feature / value stored in the node,\n",
        "    # to that of the considered example.\n",
        "    if node.crit.CompAndMatch(r):\n",
        "        return TFbranch_classify(r, node.branch_T)\n",
        "    else:\n",
        "        return TFbranch_classify(r, node.branch_F)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuY_B2Ai6QN6"
      },
      "source": [
        "def PrintTree(node, Tree_depth = 0, spacing=\"\"):\n",
        "    \"\"\"This function prints the entire decision tree.\"\"\"\n",
        "\n",
        "    # Base case\n",
        "    # case where we reached the leaf node\n",
        "    if isinstance(node, Leaf_node):\n",
        "        print(spacing + \"Leaf_node with node id \" + str(node.id) + \" Predict \" + str(node.preds) + \" Class = \" + str(node.lab_predicted))\n",
        "        return\n",
        "\n",
        "    # Print the question or the split criterion\n",
        "    print(spacing + str(node.crit) + \" Tree_depth = \" + str(node.Tree_depth) + \" id = \" + str(node.id))\n",
        "\n",
        "    # For a true branch, perform a recursive call of this function\n",
        "    print(spacing + '--> True:')\n",
        "    PrintTree(node.branch_T,  \" Tree_depth = \" + str(node.Tree_depth+1), spacing + \"  \")\n",
        "\n",
        "    # For a false  branch, perform a recursive call of this function\n",
        "    print(spacing + '--> False:')\n",
        "    PrintTree(node.branch_F,  \" Tree_depth = \" + str(node.Tree_depth+1), spacing + \"  \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A6dByRM6Txp"
      },
      "source": [
        "def PrintLeafNode(cnts):\n",
        "    tot = sum(cnts.values()) * 1.0\n",
        "    probs = {}\n",
        "    for lb in cnts.keys():\n",
        "        probs[lb] = str(int(cnts[lb] / tot * 100)) + \"%\"\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bvG2abm6XL6"
      },
      "source": [
        "def get_Node_List(node, Node_List=[], LeafNode_List=[]):\n",
        "    # Returns all nodes other than the leaf nodes\n",
        "    # Base case\n",
        "    # The case where the leaf node reached\n",
        "    spacing = ' '\n",
        "    if isinstance(node, Leaf_node):\n",
        "        LeafNode_List.append(node.id)\n",
        "        return\n",
        "\n",
        "    Node_List.append(node.id)\n",
        "\n",
        "    # For true branch, performing recursive call of this function\n",
        "    get_Node_List(node.branch_T, Node_List)\n",
        "\n",
        "    # For false branch, performing recursive call of this function\n",
        "    get_Node_List(node.branch_F, Node_List)\n",
        "\n",
        "    return Node_List, LeafNode_List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGovm5pY6bNc"
      },
      "source": [
        "def get_LeafNode_List(node, Leaf_Nodes =[]):\n",
        "\n",
        "    # This will create and track the leaf nodes.\n",
        "    # Base case\n",
        "    # The case where we reach the leaf node\n",
        "    spacing = ' '\n",
        "    if isinstance(node, Leaf_node):\n",
        "        Leaf_Nodes.append(node)\n",
        "        return\n",
        "\n",
        "    get_LeafNode_List(node.branch_T, Leaf_Nodes)\n",
        "    get_LeafNode_List(node.branch_F, Leaf_Nodes)\n",
        "\n",
        "    return Leaf_Nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuNGYJxn6fmT"
      },
      "source": [
        "inner_Nodes =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYCkuYPn6iaN"
      },
      "source": [
        "def get_Inner_Nodes(node):\n",
        "\n",
        "    # This function creates and stores the inner nodes of the graph i.e. all nodes that are neither leaf nor root nodes. \n",
        "    # Base case:\n",
        "    # The case for the leaf node is reached\n",
        "    spacing = ''\n",
        "    if isinstance(node, Leaf_node):\n",
        "        return\n",
        "\n",
        "    inner_Nodes.append(node)\n",
        "\n",
        "    get_Inner_Nodes(node.branch_T)\n",
        "    get_Inner_Nodes(node.branch_F)\n",
        "\n",
        "    return inner_Nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRfII39Q6k55"
      },
      "source": [
        "def calc_Acc(rows, node):\n",
        "  \"\"\" Function to compute the accuacy measure\"\"\"\n",
        "  num_acc = 0\n",
        "  num_rows = len(rows)\n",
        "  if num_rows == 0:\n",
        "    return 0\n",
        "  for r in rows:\n",
        "    # the last column is the lab for the dataset chosen\n",
        "    lab = r[-1]\n",
        "    pred = TFbranch_classify(r, node)\n",
        "    if lab == pred:\n",
        "      num_acc = num_acc + 1\n",
        "  return round(num_acc/num_rows, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7nk0h4-Y3ci"
      },
      "source": [
        "data1 = [list(row) for row in data.collect()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpNVg66i6xQE"
      },
      "source": [
        "header = ['ID','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','CNT_CHILDREN','AMT_INCOME_TOTAL','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','DAYS_BIRTH','DAYS_EMPLOYED','FLAG_MOBIL','FLAG_WORK_PHONE','FLAG_PHONE','FLAG_EMAIL','JOB','BEGIN_MONTHS','STATUS','TARGET']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q75hgEFS6_5M"
      },
      "source": [
        "tree = build_tree(data1,header,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmQPGfnC7JGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed47a431-1fc6-4a3e-e64a-d4c05137c9ea"
      },
      "source": [
        "PrintTree(tree)\n",
        "nodes, leafNodes = get_Node_List(tree)\n",
        "print(\"------------- Leaf nodes ------------------\")\n",
        "LNode_List = get_LeafNode_List(tree)\n",
        "for leaf in LNode_List:\n",
        "    print(\"id = \" + str(leaf.id) + \" depth =\" + str(leaf.Tree_depth))\n",
        "print(\"------------- Non-leaf nodes -----------------\")\n",
        "inner_Nodes = get_Inner_Nodes(tree)\n",
        "for inner in inner_Nodes:\n",
        "    print(\"id = \" + str(inner.id) + \" depth =\" + str(inner.Tree_depth))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is STATUS == 5? Tree_depth = 0 id = 0\n",
            "--> True:\n",
            "  Leaf_node with node id 2 Predict {1: 1087} Class = 1\n",
            "--> False:\n",
            "  Is STATUS == 2? Tree_depth = 1 id = 1\n",
            "  --> True:\n",
            "    Leaf_node with node id 4 Predict {1: 542} Class = 1\n",
            "  --> False:\n",
            "    Is STATUS == 3? Tree_depth = 2 id = 3\n",
            "    --> True:\n",
            "      Leaf_node with node id 8 Predict {1: 181} Class = 1\n",
            "    --> False:\n",
            "      Is STATUS == 4? Tree_depth = 3 id = 7\n",
            "      --> True:\n",
            "        Leaf_node with node id 16 Predict {1: 152} Class = 1\n",
            "      --> False:\n",
            "        Leaf_node with node id 15 Predict {0: 3449} Class = 0\n",
            "------------- Leaf nodes ------------------\n",
            "id = 2 depth =1\n",
            "id = 4 depth =2\n",
            "id = 8 depth =3\n",
            "id = 16 depth =4\n",
            "id = 15 depth =4\n",
            "id = 2 depth =1\n",
            "id = 4 depth =2\n",
            "id = 8 depth =3\n",
            "id = 16 depth =4\n",
            "id = 15 depth =4\n",
            "------------- Non-leaf nodes -----------------\n",
            "id = 0 depth =0\n",
            "id = 1 depth =1\n",
            "id = 3 depth =2\n",
            "id = 7 depth =3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjRYv3hF8Wfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf12abe-8af0-4fda-d312-c4a0c5d41597"
      },
      "source": [
        "max_acc=0\n",
        "Tree_Pruning(tree,inner_Nodes)\n",
        "test = data1[0]\n",
        "lab = TFbranch_classify(test, tree)\n",
        "test = data1[0:150]\n",
        "acc=calc_Acc(test, tree)\n",
        "if(acc>max_acc):\n",
        "\tmax_acc=acc\n",
        "print(\"Maximum acc = \"+str(max_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum acc = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84zy8I8T9eh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f880e3-1e70-46c0-baa9-b24d311d06fb"
      },
      "source": [
        "print(lab)\n",
        "print(tree.crit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Is STATUS == 5?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgUhLuLw9-TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98ed300-796b-430d-bf3b-f982cff201c5"
      },
      "source": [
        "df = data.randomSplit([0.2,0.8])\n",
        "trainDF = df[0]\n",
        "testDF = df[1]\n",
        "train = [list(r) for r in trainDF.collect()]\n",
        "test = [list(r) for r in testDF.collect()]\n",
        "tree = build_tree(train, header,0)\n",
        "final_acc = calc_Acc(test, tree)\n",
        "print(\"acc on test = \" + str(final_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc on test = 0.9895\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}